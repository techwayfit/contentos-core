# AI Vector Search & Image Similarity Guide

**A Beginner's Guide to Understanding Embeddings, Vector Search, and Image Similarity**

---

## Table of Contents
1. [What Are Embeddings?](#what-are-embeddings)
2. [How Vector Search Works](#how-vector-search-works)
3. [Distance Metrics Explained](#distance-metrics-explained)
4. [Search Algorithms Compared](#search-algorithms-compared)
5. [Image Search Techniques](#image-search-techniques)
6. [RAG (Retrieval Augmented Generation)](#rag-retrieval-augmented-generation)
7. [Decision Guide: Which Algorithm to Use?](#decision-guide)
8. [Implementation in ContentOS](#implementation-in-contentos)

---

## What Are Embeddings?

### The Basic Concept

**Embeddings** convert complex data (text, images, audio) into **numbers** that computers can compare.

```
Text:     "cute cat playing"
          â†“ (AI Model converts to numbers)
Embedding: [0.23, -0.15, 0.87, 0.45, -0.32, ...]  â† 512-1536 numbers
```

### Why Do We Need Embeddings?

**Problem:** How do you tell if two images are similar?
- You can't directly compare pixels (too noisy)
- File names don't capture visual content
- Tags/metadata are incomplete

**Solution:** Convert images to embeddings
```
Image A: "red car"     â†’ [0.8, 0.2, 0.1, ...]
Image B: "blue car"    â†’ [0.7, 0.3, 0.1, ...]  â† Similar! (car context)
Image C: "red apple"   â†’ [0.1, 0.9, 0.8, ...]  â† Different!
```

### Visual Representation

```
3D Space Visualization (simplified from 512 dimensions):

         Red Objects
              â†‘
              |   ğŸ (red apple)
              |
              |
    ğŸš— â† â”€ â”€ â”¼ â”€ â”€ â†’ ğŸš™  (cars cluster together)
    (red)    |    (blue)
             |
             |
          Vehicles â†’
```

**Key Insight:** Similar things are **close together** in embedding space!

---

## How Vector Search Works

### Step-by-Step Example

**Scenario:** You search for "sports car" in an image library with 1 million images.

#### Step 1: Convert Your Query to an Embedding
```
Your text: "sports car"
           â†“ (CLIP model)
Query Vector: [0.85, 0.12, -0.33, 0.67, ...]
```

#### Step 2: Compare with All Images
```
Database has 1,000,000 images, each with an embedding:

Image 1: [0.82, 0.15, -0.30, 0.65, ...] â†’ Distance: 0.08 âœ“ Very similar!
Image 2: [0.10, 0.95, -0.88, 0.22, ...] â†’ Distance: 0.92 âœ— Not similar
Image 3: [0.79, 0.18, -0.35, 0.70, ...] â†’ Distance: 0.12 âœ“ Similar!
...
Image 1M: [0.45, 0.67, 0.11, -0.22, ...] â†’ Distance: 0.55 âœ— Not similar
```

#### Step 3: Return Top Results
```
Rank   Image      Distance    Description
â”€â”€â”€â”€   â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1    Image_1     0.08       Red Ferrari
  2    Image_3     0.12       Blue Porsche
  3    Image_47    0.15       Yellow Lamborghini
  ...
```

### The Performance Problem

**Without indexing:** 
- Must compare query against ALL 1 million vectors
- 1 million distance calculations per search
- **Very slow!** (seconds to minutes)

**With indexing:**
- Smart data structures skip most comparisons
- Check only ~1,000 vectors (0.1% of database)
- **Fast!** (milliseconds)

---

## Distance Metrics Explained

### 1. Cosine Similarity (Most Common)

**What it measures:** The **angle** between two vectors (ignores length)

#### Visual Explanation
```
         Vector A (long)
              â†—
             /
            /
           / 15Â° angle â† Small angle = Very similar!
          /
         /
        â†— Vector B (short)
       /
      /
```

```
         Vector C
              â†—
             /
            /
           / 85Â° angle â† Large angle = Not similar
          /
    â†â”€â”€â”€â”€â”˜
    Vector D
```

**Formula:**
```
Similarity = cos(Î¸) = (A Â· B) / (|A| Ã— |B|)

Results:
  1.0  = Identical direction (perfect match)
  0.5  = 60Â° angle (somewhat similar)
  0.0  = 90Â° angle (unrelated)
 -1.0  = 180Â° angle (opposite)
```

**When to use:**
- âœ… Image embeddings (CLIP, ResNet)
- âœ… Text embeddings (GPT, BERT)
- âœ… When embeddings are normalized to unit length

**SQL Example:**
```sql
-- pgvector operator: <=>
-- Lower distance = more similar
SELECT * FROM IMAGE_EMBEDDING 
ORDER BY embedding_vector <=> $query_vector 
LIMIT 10;
```

---

### 2. Euclidean Distance (L2)

**What it measures:** Straight-line distance in space (like measuring with a ruler)

#### Visual Explanation
```
2D Space:

Point A (3, 8) â—
               |â•²
               | â•²
               |  â•²  Distance = âˆš[(5-3)Â² + (5-8)Â²]
               |   â•²             = âˆš[4 + 9] = 3.6
               |    â•²
               |     â•²
Point B (5, 5) â”€â”€â”€â”€â”€â”€â— 
```

**Formula:**
```
Distance = âˆš[(xâ‚-xâ‚‚)Â² + (yâ‚-yâ‚‚)Â² + ... + (zâ‚-zâ‚‚)Â²]
```

**Real Example:**
```
Image A: [0.8, 0.2, 0.5]
Image B: [0.7, 0.3, 0.4]
Distance = âˆš[(0.8-0.7)Â² + (0.2-0.3)Â² + (0.5-0.4)Â²]
         = âˆš[0.01 + 0.01 + 0.01] = 0.17
```

**When to use:**
- âœ… Non-normalized embeddings
- âœ… When magnitude matters (e.g., confidence scores)
- âš ï¸ Sensitive to scale (one large dimension can dominate)

**SQL Example:**
```sql
-- pgvector operator: <->
SELECT * FROM IMAGE_EMBEDDING 
ORDER BY embedding_vector <-> $query_vector 
LIMIT 10;
```

---

### 3. Dot Product (Inner Product)

**What it measures:** How much two vectors "align" (includes magnitude)

#### Visual Explanation
```
Long vectors = Higher scores

Vector A (long) â”€â”€â”€â”€â”€â”€â”€â”€â†’
                 â†—
Vector B (short) â†’  Small angle + different lengths
                    Dot Product = |A| Ã— |B| Ã— cos(Î¸)
```

**Formula:**
```
Dot Product = (aâ‚ Ã— bâ‚) + (aâ‚‚ Ã— bâ‚‚) + ... + (aâ‚™ Ã— bâ‚™)
```

**Real Example:**
```
Vector A: [0.5, 0.8, 0.3]
Vector B: [0.6, 0.7, 0.4]
Dot Product = (0.5Ã—0.6) + (0.8Ã—0.7) + (0.3Ã—0.4)
            = 0.30 + 0.56 + 0.12 = 0.98
```

**When to use:**
- âœ… **Fastest** computation (no sqrt needed)
- âœ… Normalized embeddings
- âœ… When you need maximum speed

---

### Comparison Example

**Same query, different metrics:**

```
Query:    [1.0, 0.0, 0.0]
Image A:  [0.9, 0.1, 0.0]  
Image B:  [0.0, 1.0, 0.0]  
Image C:  [0.5, 0.5, 0.0]

Metric          Image A    Image B    Image C    Winner
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€
Cosine Sim       0.994      0.000      0.707     A (highest)
Euclidean        0.141      1.414      0.707     A (lowest)
Dot Product      0.900      0.000      0.500     A (highest)
                 â†‘ All agree: Image A is most similar!
```

---

## Search Algorithms Compared

### The Challenge: Searching Large Databases

**Problem:**
- 1 million images Ã— 512 numbers each = 512 million comparisons per search!
- At 1 microsecond per comparison = 0.5 seconds minimum
- **Too slow for real-time search**

**Solution:** Use indexes to skip most comparisons

---

### Algorithm 1: Brute Force KNN (Baseline)

**How it works:**
```
Query: "red car"

Check ALL images:
[âœ“] Image 1     distance: 0.15
[âœ“] Image 2     distance: 0.82
[âœ“] Image 3     distance: 0.23
[âœ“] Image 4     distance: 0.91
...
[âœ“] Image 1M    distance: 0.67

Sort by distance â†’ Return top 10
```

**Diagram:**
```
Query â†’  [Compare] â†’ Image 1
     â†’  [Compare] â†’ Image 2
     â†’  [Compare] â†’ Image 3
     â†’  [Compare] â†’ ...
     â†’  [Compare] â†’ Image 1,000,000
                     â†“
                  Sort & Return Top 10
```

**Pros:**
- âœ… 100% accuracy (finds exact nearest neighbors)
- âœ… Simple to implement
- âœ… No setup/training needed

**Cons:**
- âŒ O(n) complexity (linear with database size)
- âŒ **Very slow** for large datasets

**When to use:**
- Fewer than 10,000 images
- Development/testing
- When you need perfect accuracy

---

### Algorithm 2: IVFFlat (Inverted File with Flat Compression)

**How it works: Cluster-based search**

#### Step 1: Training Phase (One-time setup)
```
Group all 1M images into 100 clusters using k-means:

Cluster 1: Sports cars      (10,000 images)
Cluster 2: Sedans           (15,000 images)
Cluster 3: Cats             (8,000 images)
...
Cluster 100: Mountains      (12,000 images)
```

#### Step 2: Search Phase
```
Query: "red sports car"
  â†“
Find 5 nearest cluster centers:
  Cluster 1: Sports cars     (distance: 0.2) âœ“ Check this
  Cluster 2: Sedans          (distance: 0.4) âœ“ Check this
  Cluster 78: Red objects    (distance: 0.5) âœ“ Check this
  Cluster 99: Cats           (distance: 0.9) âœ— Skip
  Cluster 100: Mountains     (distance: 0.95) âœ— Skip
  â†“
Only search ~30,000 images (3% of database!)
```

**Visual Diagram:**
```
Database with 100 clusters:

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Cluster â”‚  10K sports cars
     â”‚    1    â”‚  â† Query is closest to this cluster
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘
        / \
       /   \
  Query    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  "red     â”‚ Cluster â”‚  15K sedans
  sports   â”‚    2    â”‚  â† Also close, check this
   car"    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      
      Far clusters (skipped):
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚Cluster 3â”‚  â”‚Cluster 4â”‚
      â”‚  Cats   â”‚  â”‚Mountainsâ”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Configuration:**
```sql
CREATE INDEX idx_image_ivfflat 
  ON IMAGE_EMBEDDING USING ivfflat (embedding_vector vector_cosine_ops)
  WITH (lists = 100);
  
-- Tuning guide:
-- lists = sqrt(total_rows) for balanced performance
-- More lists = faster search, but lower recall
```

**Trade-offs:**
```
Clusters  Images Checked  Speed      Recall
â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€
  10          100,000      5x faster   98%
  100         10,000       50x faster  95%
  1000        1,000        500x faster 85%
```

**Pros:**
- âœ… **10-100x faster** than brute force
- âœ… Fast to build (minutes for 1M vectors)
- âœ… Good recall (90-95%)

**Cons:**
- âŒ Not 100% accurate (might miss some results)
- âŒ Requires tuning `lists` parameter
- âŒ Quality depends on cluster quality

**When to use:**
- 100K - 10M images
- When 90-95% recall is acceptable
- Rapid development/iteration

---

### Algorithm 3: HNSW (Hierarchical Navigable Small World)

**How it works: Multi-layer graph navigation**

Think of it like **hierarchical map navigation:**
- **Layer 3 (top):** Interstate highways (sparse, long jumps)
- **Layer 2:** State highways (medium density)
- **Layer 1:** City streets (dense connections)
- **Layer 0 (bottom):** Every image (complete graph)

#### Visual Diagram
```
Layer 3 (sparse):    A â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ B
                     â†“                     â†“
                     
Layer 2 (medium):    C â†’ D â†’ E            F â†’ G
                     â†“   â†“   â†“            â†“   â†“
                     
Layer 1 (dense):     Hâ”€Iâ”€Jâ”€Kâ”€L          Mâ”€Nâ”€Oâ”€P
                     â†“ â†“ â†“ â†“ â†“          â†“ â†“ â†“ â†“
                     
Layer 0 (all):       [10,000 images with local connections]
```

#### Search Process
```
Query: "Find similar to this cat image"

Step 1: Start at top layer (Layer 3)
  Current: Node A
  Check neighbors: B is closer â†’ Jump to B
  
Step 2: Drop to Layer 2
  Current: Node B â†’ Maps to Node F
  Check neighbors: G is closer â†’ Move to G
  
Step 3: Drop to Layer 1
  Current: Node G â†’ Maps to Node N
  Check neighbors: O, P â†’ P is closest
  
Step 4: Layer 0 (ground level)
  Current: Node P
  Check all neighbors in detail
  Found: Top 10 most similar images!
  
Total checks: ~50 nodes (out of 1,000,000!)
```

**Configuration:**
```sql
CREATE INDEX idx_image_hnsw 
  ON IMAGE_EMBEDDING USING hnsw (embedding_vector vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

-- Parameters explained:
-- m = 16:  Each node connects to 16 neighbors (more = better recall)
-- ef_construction = 64: Search width during building (higher = better quality)

-- Query-time tuning:
SET hnsw.ef_search = 100;  -- Search more neighbors at runtime
```

**Pros:**
- âœ… **Best recall** (>99%) at high speed
- âœ… Scalable to billions of vectors
- âœ… Consistent query performance (log-like)

**Cons:**
- âŒ **Slow to build** (hours for 10M+ vectors)
- âŒ More memory usage than IVFFlat
- âŒ Updates are expensive (not for high-write workloads)

**When to use:**
- Production systems
- >1M images
- When recall/accuracy is critical
- Read-heavy workload

---

### Algorithm Comparison Chart

```
Algorithm     Speed        Recall    Build Time   Memory    Best For
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Brute Force   Slowest      100%      None         Low       <10K images
IVFFlat       Fast (50x)   90-95%    Minutes      Medium    100K-10M images
HNSW          Fast (100x)  >99%      Hours        High      >1M images, prod
Product Quant Ultra-fast   85-90%    Hours        Very Low  >100M images
```

---

## Image Search Techniques

### 1. Direct Image Similarity (What You've Used)

**Scenario:** "Find images similar to this one"

```
User uploads:  ğŸš— (image of red car)
              â†“ (Convert to embedding)
Query Vector: [0.8, 0.2, 0.5, ...]
              â†“ (Search database)
Results:      ğŸš— ğŸš™ ğŸï¸ (similar cars)
```

**SQL:**
```sql
SELECT attachment_id, file_name
FROM IMAGE_EMBEDDING
WHERE tenant_id = $tenant_id
ORDER BY embedding_vector <=> $uploaded_image_embedding
LIMIT 10;
```

---

### 2. Text-to-Image Search (Multimodal)

**The Magic:** Search images using **text descriptions**!

**How it works with CLIP (Contrastive Language-Image Pre-training):**

```
Training Phase (done by OpenAI):
  Image: ğŸ±         Text: "cute cat"
         â†“                  â†“
    CLIP Image          CLIP Text
      Encoder            Encoder
         â†“                  â†“
    [0.2, 0.8, ...]    [0.2, 0.8, ...]  â† Same embedding space!
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              Embeddings are close together
```

**Your Search:**
```
User types: "red sports car at sunset"
           â†“ (CLIP Text Encoder)
Text Vector: [0.85, 0.12, -0.33, ...]
           â†“ (Search image embeddings)
Results:    ğŸï¸ğŸŒ… ğŸš—ğŸŒ† ğŸğŸŒ„ (matching images!)
```

**SQL:**
```sql
-- Text query converted to embedding via CLIP
SELECT ie.attachment_id, a.file_name, a.storage_path
FROM IMAGE_EMBEDDING ie
JOIN ATTACHMENT a ON ie.attachment_id = a.id
WHERE ie.tenant_id = $tenant_id
  AND ie.embedding_model = 'clip-vit-large-patch14'  -- Must use CLIP!
ORDER BY ie.embedding_vector <=> $text_query_embedding
LIMIT 10;
```

**Why CLIP is Special:**
- âœ… Shared embedding space (text and images)
- âœ… No need for manual tags/labels
- âœ… Understands context ("beach at sunset" â‰  "beach at noon")

---

### 3. Hybrid Search (Vector + Metadata)

**Problem:** Pure vector search ignores useful metadata

**Example:**
```
User: "Find large images of red cars"
      â†‘         â†‘              â†‘
   Metadata  Metadata      Semantic
```

**Two-stage filtering:**
```
Stage 1: Metadata filters (fast database index)
  - width >= 1920
  - height >= 1080
  - dominant_color = 'red'
  â†“ Reduces 1M images to 50K

Stage 2: Vector search on filtered set
  - embedding_vector <=> query_vector
  â†“ Returns top 10 from 50K
```

**SQL:**
```sql
SELECT ie.attachment_id, a.file_name,
       ie.embedding_vector <=> $query_vector AS similarity
FROM IMAGE_EMBEDDING ie
JOIN ATTACHMENT a ON ie.attachment_id = a.id
WHERE ie.tenant_id = $tenant_id
  -- Metadata filters (uses regular indexes)
  AND (ie.image_metadata->>'width')::int >= 1920
  AND (ie.image_metadata->>'height')::int >= 1080
  AND ie.image_metadata->'dominant_colors' ? 'red'
  -- Vector search on filtered subset
ORDER BY similarity
LIMIT 10;
```

**Performance Impact:**
```
Without metadata filtering:  Search 1,000,000 vectors
With metadata filtering:     Search 50,000 vectors (20x faster!)
```

---

### 4. Color-Based Search

**Technique:** Combine embeddings with color histograms

**Color Histogram:**
```
Image:  ğŸŒ… (sunset photo)

Red:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 60%
Orange:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 30%
Yellow:  â–ˆâ–ˆâ–ˆ 10%
Blue:    â–ˆ 5%
Other:   1%

Histogram Vector: [0.60, 0.30, 0.10, 0.05, 0.01]
```

**Combined Scoring:**
```
Result Score = (0.7 Ã— Semantic Similarity) + (0.3 Ã— Color Similarity)

Example:
  Image A: Sports car (red) 
    Semantic: 0.9 (very similar car)
    Color:    0.8 (red matches)
    Combined: 0.7Ã—0.9 + 0.3Ã—0.8 = 0.87 âœ“ Best match
    
  Image B: Sports car (blue)
    Semantic: 0.9 (very similar car)
    Color:    0.2 (color doesn't match)
    Combined: 0.7Ã—0.9 + 0.3Ã—0.2 = 0.69 âœ— Lower rank
```

---

### 5. Perceptual Hashing (Duplicate Detection)

**Different from embeddings!** Finds **exact or near-exact** duplicates.

**How it works:**
```
Original Image:     Resize to 8Ã—8    Convert to grayscale    Compare pixels
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ           â”‚ â†’  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â”‚   â†’    â”‚76543210â”‚  â†’ Hash: 10110010...
â”‚   (1920px)  â”‚    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â”‚        â”‚87654321â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   64 pixels          64-bit hash
```

**Finding duplicates:**
```
Hash A: 10110010101...  (Original image)
Hash B: 10110010100...  (Same image, slightly compressed)
        â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘
        Differs in only 1 bit â†’ Same image!

Hamming Distance = count different bits
  0 bits different  = Identical
  1-5 bits different = Near duplicate (crop, compress)
  10+ bits different = Different images
```

**Use cases:**
- âœ… Deduplication (storage savings)
- âœ… Copyright detection
- âœ… Prevent duplicate uploads

**SQL:**
```sql
-- XOR hashes and count different bits
SELECT attachment_id, file_name,
       bit_count(phash # $query_phash) AS hamming_distance
FROM IMAGE_PHASH
WHERE bit_count(phash # $query_phash) <= 5  -- 5-bit threshold
ORDER BY hamming_distance;
```

---

## RAG (Retrieval Augmented Generation)

### What is RAG?

**Problem:** AI models have limited knowledge (training data cutoff)

**Solution:** Give AI access to **your documents** at query time

```
Traditional AI:
  User: "What's our return policy?"
        â†“
  AI (from training data): "I don't have access to specific policies..."
  âŒ Not helpful

RAG-Enhanced AI:
  User: "What's our return policy?"
        â†“
  Step 1: Search your documents â†’ Find "Return Policy v3.2"
        â†“
  Step 2: Pass document + question to AI
        â†“
  AI: "According to your policy, you offer 30-day returns..."
  âœ… Accurate, up-to-date!
```

### RAG Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG SYSTEM                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  User Question: "What's our return policy?"              â”‚
â”‚        â†“                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  STEP 1: RETRIEVAL                    â”‚               â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚               â”‚
â”‚  â”‚  1. Convert question to embedding      â”‚               â”‚
â”‚  â”‚  2. Search CONTENT_RAG_CHUNKS table   â”‚               â”‚
â”‚  â”‚  3. Find top 5 relevant chunks         â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â†“                                                  â”‚
â”‚  Retrieved Context:                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Chunk 1: "30-day return policy..." â”‚                 â”‚
â”‚  â”‚ Chunk 2: "Items must be unused..." â”‚                 â”‚
â”‚  â”‚ Chunk 3: "Original packaging..."   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚        â†“                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  STEP 2: AUGMENTATION                 â”‚               â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚               â”‚
â”‚  â”‚  Build prompt with context:            â”‚               â”‚
â”‚  â”‚                                         â”‚               â”‚
â”‚  â”‚  "Context: [chunks above]              â”‚               â”‚
â”‚  â”‚   Question: What's our return policy?  â”‚               â”‚
â”‚  â”‚   Answer based on context above:"      â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â†“                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  STEP 3: GENERATION                    â”‚               â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚               â”‚
â”‚  â”‚  Send to AI (GPT-4, Claude, etc.)      â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â†“                                                  â”‚
â”‚  AI Response:                                             â”‚
â”‚  "According to the policy, you have 30 days to           â”‚
â”‚   return items. They must be unused and in original      â”‚
â”‚   packaging..."                                           â”‚
â”‚        â†“                                                  â”‚
â”‚  User receives accurate answer with citations!           â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Chunking is Critical

**Problem:** Documents are too long for AI context windows

```
Full Document (10,000 words):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Section 1: Introduction (1000 words)   â”‚
â”‚ Section 2: Returns (500 words) â† âœ“    â”‚
â”‚ Section 3: Shipping (2000 words)       â”‚
â”‚ Section 4: Warranties (3000 words)     â”‚
â”‚ Section 5: Contact (500 words)         â”‚
â”‚ ... (3000 more words)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ Too long! Can't fit in context
      
Chunked Approach:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1:   â”‚ â”‚ Chunk 2:   â”‚ â”‚ Chunk 3:   â”‚
â”‚ Intro      â”‚ â”‚ Returns âœ“  â”‚ â”‚ Shipping   â”‚
â”‚ (500 words)â”‚ â”‚ (500 words)â”‚ â”‚ (500 words)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†‘
              Only this chunk is relevant!
              Send just this to AI
```

### Chunking Strategy

**Option 1: Fixed-size chunking**
```
Document: "The quick brown fox jumps over the lazy dog. The dog was sleeping..."

Chunk size: 10 words, Overlap: 3 words

Chunk 1: "The quick brown fox jumps over the lazy dog. The"
Chunk 2: "dog. The dog was sleeping under the tree. Birds"
                â†‘â†‘â†‘ Overlap ensures context continuity
```

**Option 2: Semantic chunking (better)**
```
Document with sections:
  # Introduction
  This is the introduction...
  
  # Return Policy          â† Chunk boundary
  30-day returns...
  
  # Shipping Policy        â† Chunk boundary
  Free shipping over $50...

Chunks align with document structure!
```

### Three-Table RAG Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TABLE STRUCTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  CONTENT_RAG_CHUNKS (Text management)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ id: uuid-123                            â”‚             â”‚
â”‚  â”‚ source_id: content-item-456             â”‚             â”‚
â”‚  â”‚ chunk_index: 2                          â”‚             â”‚
â”‚  â”‚ chunk_text: "30-day return policy..."   â”‚ â† For display
â”‚  â”‚ chunk_tokens: 150                       â”‚             â”‚
â”‚  â”‚ metadata: {section: "returns", page: 5} â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚        â†“ One-to-many                                      â”‚
â”‚                                                           â”‚
â”‚  CONTENT_EMBEDDING (Search vectors)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ id: embedding-789                       â”‚             â”‚
â”‚  â”‚ chunk_id: uuid-123  â† Links to chunk   â”‚             â”‚
â”‚  â”‚ embedding_model: "text-ada-002"         â”‚             â”‚
â”‚  â”‚ embedding_vector: [0.23, -0.15, ...]    â”‚ â† Searchable
â”‚  â”‚ locale: "en-US"                         â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                           â”‚
â”‚  IMAGE_EMBEDDING (Separate for images)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ id: img-embedding-999                   â”‚             â”‚
â”‚  â”‚ attachment_id: image-888                â”‚             â”‚
â”‚  â”‚ embedding_model: "clip-vit-large"       â”‚             â”‚
â”‚  â”‚ embedding_vector: [0.87, 0.45, ...]     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RAG Query Flow

```sql
-- Step 1: User asks question
-- "What's the return policy?"
-- â†“ Convert to embedding via OpenAI

-- Step 2: Search for relevant chunks
WITH ranked_chunks AS (
  SELECT 
    ce.chunk_id,
    crc.chunk_text,
    crc.chunk_metadata,
    ce.embedding_vector <=> $question_embedding AS similarity
  FROM CONTENT_EMBEDDING ce
  JOIN CONTENT_RAG_CHUNKS crc ON ce.chunk_id = crc.id
  WHERE ce.tenant_id = $tenant_id
    AND ce.locale = 'en-US'
    AND crc.is_active = true
  ORDER BY similarity
  LIMIT 5
)
SELECT chunk_text FROM ranked_chunks;

-- Step 3: Results
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ "30-day return policy for all items..."  â”‚
-- â”‚ "Items must be unused and in original..." â”‚
-- â”‚ "Refunds processed within 7 business..." â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- Step 4: Build prompt
-- Context: [chunks above]
-- Question: What's the return policy?
-- Answer:

-- Step 5: Send to GPT-4 â†’ Get answer with citations!
```

---

## Decision Guide

### Flowchart: Which Algorithm Should I Use?

```
START: How many images/documents?
  â”‚
  â”œâ”€ < 10,000
  â”‚    â””â”€â†’ Use: BRUTE FORCE (no index)
  â”‚        - Simple, 100% accurate
  â”‚        - Fast enough for small datasets
  â”‚
  â”œâ”€ 10,000 - 100,000
  â”‚    â””â”€â†’ Use: IVFFlat (lists = 100)
  â”‚        - Good balance of speed and accuracy
  â”‚        - Fast to build
  â”‚
  â”œâ”€ 100,000 - 10,000,000
  â”‚    â”‚
  â”‚    â”œâ”€ Need max speed? (90% accuracy OK?)
  â”‚    â”‚   â””â”€â†’ Use: IVFFlat (lists = 1000)
  â”‚    â”‚
  â”‚    â””â”€ Need max accuracy? (can wait for indexing?)
  â”‚        â””â”€â†’ Use: HNSW (m=16, ef=64)
  â”‚
  â””â”€ > 10,000,000
       â”‚
       â”œâ”€ Limited memory?
       â”‚   â””â”€â†’ Use: Product Quantization (external system)
       â”‚
       â””â”€ Have memory?
           â””â”€â†’ Use: HNSW (m=32, ef=128)
```

### Quick Reference Table

| Your Situation | Recommended Approach |
|----------------|---------------------|
| **Just learning AI** | Start with cosine similarity + brute force |
| **Building MVP** | IVFFlat index, 90% recall is fine |
| **Production system** | HNSW for best quality |
| **Text â†’ Image search** | Use CLIP embeddings + text-to-image |
| **Find duplicates** | Perceptual hashing (phash) |
| **Content search for AI** | RAG with chunking |
| **Limited budget** | IVFFlat (cheaper than HNSW) |
| **Need 99%+ accuracy** | HNSW or brute force |

---

## Implementation in ContentOS

### Database Schema

```sql
-- 1. Text chunks (no embeddings, just text management)
CREATE TABLE CONTENT_RAG_CHUNKS (
  id UUID PRIMARY KEY,
  tenant_id UUID NOT NULL,
  source_type VARCHAR(50),      -- 'content_item', 'attachment', 'comment'
  source_id UUID,
  chunk_index INT,
  chunk_text TEXT,              -- Original text for citations
  chunk_tokens INT,
  chunk_metadata JSONB,         -- {section, page, heading}
  created_on TIMESTAMP,
  is_active BOOLEAN
);

-- 2. Text embeddings (for semantic search)
CREATE TABLE CONTENT_EMBEDDING (
  id UUID PRIMARY KEY,
  tenant_id UUID NOT NULL,
  chunk_id UUID REFERENCES CONTENT_RAG_CHUNKS(id),
  embedding_model VARCHAR(100),
  embedding_vector vector(1536),  -- Adjust dimension per model
  locale VARCHAR(10),
  tags TEXT[],
  indexed_at TIMESTAMP,
  is_active BOOLEAN
);

-- Vector index for fast search
CREATE INDEX idx_content_embedding_vector 
  ON CONTENT_EMBEDDING USING hnsw (embedding_vector vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

-- 3. Image embeddings (separate table for different needs)
CREATE TABLE IMAGE_EMBEDDING (
  id UUID PRIMARY KEY,
  tenant_id UUID NOT NULL,
  attachment_id UUID REFERENCES ATTACHMENT(id),
  embedding_model VARCHAR(100),
  embedding_vector vector(512),   -- CLIP uses 512 dims
  image_metadata JSONB,
  created_on TIMESTAMP,
  is_active BOOLEAN
);

-- Vector index for image search
CREATE INDEX idx_image_embedding_vector 
  ON IMAGE_EMBEDDING USING hnsw (embedding_vector vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);
```

### Example Queries

#### 1. Simple Image Similarity
```sql
-- Find images similar to uploaded image
SELECT ie.attachment_id, a.file_name,
       ie.embedding_vector <=> $query_embedding AS similarity
FROM IMAGE_EMBEDDING ie
JOIN ATTACHMENT a ON ie.attachment_id = a.id
WHERE ie.tenant_id = $tenant_id
ORDER BY similarity
LIMIT 10;
```

#### 2. Text-to-Image Search (CLIP)
```sql
-- Search images using text query
SELECT ie.attachment_id, a.file_name,
       ie.embedding_vector <=> $text_query_embedding AS similarity
FROM IMAGE_EMBEDDING ie
JOIN ATTACHMENT a ON ie.attachment_id = a.id
WHERE ie.tenant_id = $tenant_id
  AND ie.embedding_model LIKE 'clip%'  -- Must use multimodal model
ORDER BY similarity
LIMIT 10;
```

#### 3. RAG Document Search
```sql
-- Find relevant document chunks for AI
SELECT crc.chunk_text, crc.chunk_metadata,
       ce.embedding_vector <=> $question_embedding AS relevance
FROM CONTENT_EMBEDDING ce
JOIN CONTENT_RAG_CHUNKS crc ON ce.chunk_id = crc.id
WHERE ce.tenant_id = $tenant_id
  AND ce.locale = 'en-US'
  AND crc.is_active = true
ORDER BY relevance
LIMIT 5;
```

#### 4. Hybrid Search (Metadata + Vector)
```sql
-- Combine filters with semantic search
SELECT ie.attachment_id, a.file_name,
       ie.embedding_vector <=> $query_embedding AS similarity
FROM IMAGE_EMBEDDING ie
JOIN ATTACHMENT a ON ie.attachment_id = a.id
WHERE ie.tenant_id = $tenant_id
  AND ie.is_active = true
  -- Metadata filters (fast index lookup)
  AND (ie.image_metadata->>'width')::int >= 1024
  AND ie.image_metadata->'dominant_colors' ? 'blue'
  -- Vector search on filtered subset
ORDER BY similarity
LIMIT 10;
```

---

## Key Takeaways

### For Beginners

1. **Embeddings = Numbers representing meaning**
   - Images, text, audio â†’ Arrays of numbers
   - Similar things have similar numbers

2. **Distance = Similarity**
   - Cosine similarity: Most common (use this!)
   - Smaller distance = more similar

3. **Indexes = Speed**
   - Small dataset (<10K): No index needed
   - Medium (10K-1M): Use IVFFlat
   - Large (>1M): Use HNSW

4. **Start Simple, Scale Up**
   - Begin with brute force search
   - Add IVFFlat when slow
   - Move to HNSW for production

### Common Mistakes to Avoid

âŒ **Using wrong distance metric**
   - CLIP embeddings â†’ Use cosine similarity
   - Don't mix metrics from different models

âŒ **Not filtering by tenant**
   - Always filter `WHERE tenant_id = $tenant_id` first
   - Security + performance

âŒ **Forgetting to normalize embeddings**
   - If using dot product, normalize to unit length
   - Cosine similarity handles this automatically

âŒ **Building HNSW index for small datasets**
   - Overkill for <100K vectors
   - Takes hours to build, no benefit

âŒ **Not chunking for RAG**
   - Long documents don't fit in AI context
   - Chunk to 500-1000 tokens

---

## Next Steps

### Phase 1: Learning (Now)
- âœ… Understand concepts (this document)
- âœ… Experiment with small dataset (<1K images)
- âœ… Use cosine similarity + brute force

### Phase 2: Development
- Add CONTENT_RAG_CHUNKS, CONTENT_EMBEDDING, IMAGE_EMBEDDING tables
- Implement basic search endpoints
- Test with IVFFlat index

### Phase 3: Production
- Switch to HNSW for better recall
- Add hybrid search (metadata + vectors)
- Implement RAG for AI features

### Phase 4: Optimization
- Monitor performance metrics
- Tune index parameters
- Add re-ranking, diversity filters

---

## Glossary

| Term | Simple Explanation |
|------|-------------------|
| **Embedding** | Numbers representing meaning of text/image/etc |
| **Vector** | Array of numbers (e.g., [0.23, -0.15, 0.87]) |
| **Dimension** | How many numbers in a vector (512, 1536, etc.) |
| **Cosine Similarity** | Measure of angle between vectors (0-1) |
| **KNN** | K-Nearest Neighbors - find K most similar items |
| **Index** | Data structure for fast search (like book index) |
| **IVFFlat** | Index using clusters (fast, 90% accuracy) |
| **HNSW** | Index using graph (fastest, 99% accuracy) |
| **CLIP** | AI model for text + image embeddings |
| **RAG** | Retrieval Augmented Generation (AI + search) |
| **Chunking** | Splitting documents into smaller pieces |
| **Multimodal** | Works with multiple types (text + images) |
| **Perceptual Hash** | Fingerprint for duplicate detection |

---

**Document Version:** 1.0  
**Last Updated:** January 5, 2026  
**Author:** ContentOS Team  
**Purpose:** Educational guide for AI/ML beginners implementing vector search
